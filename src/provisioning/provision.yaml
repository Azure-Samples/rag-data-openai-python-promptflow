ai:
  # you must specify an existing subscription
  subscription_id: "<my_subscription_id>"
  # you can specify an existing resource group or specify the name for one to be created for you
  resource_group_name: "<my_resource_group_name>"
  # you must specify what region to use for your ai services.
  # We recommend using the check_quota script provided before picking a region, or looking at model availability: https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models#standard-deployment-model-availability
  location: "<my_location>" # e.g. swedencentral

  # reference existing AI Hub+Project resources, or specify the name you want for new resources.
  # If you specify an existing hub but a non-existing project, a new project in that hub will be created for you.
  hub_name: "<my_ai_hub_name>"
  project_name: "<my_ai_project_name>"

aoai:
  # use references to an existing AOAI resource to connect it to your hub
  # or else provision.py will create a resource with those references

  # uncomment these only if sub/rg/region are different from AI Hub
  # subscription_id: "<my_subscription_id>"
  # resource_group_name: "<my_resource_group>"
  # IMPORTANT: for assistant, region needs to be in [australiaeast, eastus, eastus2, francecentral, norwayeast, swedencentral, uksouth]
  # location: <my_location>

  # you can find the resource name and connection name under project Settings -> Connected resources.
  # alternatively, the name is the first part of the endpoint, after the protocol.
  aoai_resource_name: "<my_aoai_resource_name>"
  kind: "OpenAI" # use OpenAI for AIServices

  # specify the name of the existing/creating hub connection for this resource
  connection_name: "<my_aoai_connection_name>"
  
  # specify existing deployments or specify new deployments to be created
  # you can find the deployment details on the Deployments page of your project in Azure AI Studio
  deployments:
    - name: "gpt-4"
      model: "gpt-4"
      version: "turbo-2024-04-09"
    - name: "gpt-4o"
      model: "gpt-4o"
      version: "2024-05-13"
    - name: "gpt-35-turbo"
      model: "gpt-35-turbo"
      version: "0301" # if you don't know, comment this line and we'll pick default
      # capacity: 30 # choose the capacity (in thousands of tokens per minute) if you are creating a new deployment - the default is 10 if unspecified. Some regions/locations or models may have quota limits.
    - name: "text-embedding-ada-002"
      model: "text-embedding-ada-002"
      version: "2" # if you don't know, comment this line and we'll pick default


search:
  # uncomment these only if sub/rg/region are different from AI Hub
  # subscription_id: "<my_subscription_id>"
  # resource_group_name: "<my_resource_group>"
  # region: <my_region>
  
  # you can find the resource name and connection name under project Settings -> Connected resources.
  # alternatively, the name is the first part of the endpoint, after the protocol.
  search_resource_name: "<my_search_resource_name>"
  # specify the name of the existing/creating hub connection for this resource.
  connection_name: <my_search_connection_name> # this needs to match with name used for env vars below

environment:
  # below will be used for --export-env argument
  variables:
    # these env vars are drawn from the AI hub connections
    AZURE_OPENAI_CONNECTION_NAME: "${aoai.connection_name}"
    AZURE_OPENAI_ENDPOINT: "azureml://connections/${aoai.connection_name}/target"
    AZURE_SEARCH_CONNECTION_NAME: "${search.connection_name}"
    AZURE_SEARCH_ENDPOINT: "azureml://connections/${search.connection_name}/target"
    # these are constants used by this sample code - they can be modified for your use cases
    AZURE_OPENAI_API_VERSION: "2023-03-15-preview"
    AZURE_OPENAI_CHAT_DEPLOYMENT: "${aoai.deployments[0].name}"
    AZURE_OPENAI_EMBEDDING_DEPLOYMENT: "${aoai.deployments[1].name}"
    AZURE_OPENAI_EVALUATION_DEPLOYMENT: "${aoai.deployments[0].name}"